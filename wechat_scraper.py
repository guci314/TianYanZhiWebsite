#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¾®ä¿¡å…¬ä¼—å·æ–‡ç« æŠ“å–å™¨
ä½¿ç”¨ Playwright ç»•è¿‡åçˆ¬è™«æœºåˆ¶æŠ“å–å¾®ä¿¡å…¬ä¼—å·æ–‡ç« å†…å®¹
"""

import asyncio
import json
import random
import time
from datetime import datetime
from pathlib import Path
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError


class WeChatScraper:
    def __init__(self):
        self.max_retries = 3
        self.delay_range = (2, 5)
        self.user_agents = [
            'Mozilla/5.0 (iPhone; CPU iPhone OS 15_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.6 Mobile/15E148 Safari/604.1',
            'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1',
            'Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Mobile/15E148 Safari/604.1'
        ]
    
    async def setup_browser(self):
        """è®¾ç½®æµè§ˆå™¨å®ä¾‹"""
        browser = await self.playwright.chromium.launch(
            headless=False,  # è®¾ç½®ä¸º False ä»¥ä¾¿è§‚å¯Ÿå’Œæ‰‹åŠ¨å¤„ç†éªŒè¯
            args=[
                '--no-first-run',
                '--disable-blink-features=AutomationControlled',
                '--disable-web-security',
                '--disable-features=VizDisplayCompositor',
                '--disable-dev-shm-usage',
                '--no-sandbox',
                '--disable-gpu',
                '--disable-extensions',
                '--disable-plugins',
                '--disable-images',  # ç¦ç”¨å›¾ç‰‡åŠ è½½ä»¥åŠ å¿«é€Ÿåº¦
            ]
        )
        
        # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡ï¼Œæ¨¡æ‹ŸiPhone
        context = await browser.new_context(
            user_agent=random.choice(self.user_agents),
            viewport={'width': 375, 'height': 812},
            device_scale_factor=2,
            is_mobile=True,
            has_touch=True,
            extra_http_headers={
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Cache-Control': 'no-cache',
                'Pragma': 'no-cache',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Upgrade-Insecure-Requests': '1'
            }
        )
        
        page = await context.new_page()
        
        # æ³¨å…¥åæ£€æµ‹è„šæœ¬
        await page.add_init_script("""
            // ç§»é™¤ webdriver å±æ€§
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined,
            });
            
            // ä¿®æ”¹ plugins
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5],
            });
            
            // ä¿®æ”¹è¯­è¨€
            Object.defineProperty(navigator, 'languages', {
                get: () => ['zh-CN', 'zh', 'en'],
            });
            
            // éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
            Object.defineProperty(navigator, 'permissions', {
                get: () => ({
                    query: () => Promise.resolve({ state: 'granted' }),
                }),
            });
            
            // æ¨¡æ‹Ÿæ­£å¸¸çš„å±å¹•å±æ€§
            Object.defineProperty(screen, 'availHeight', { get: () => 812 });
            Object.defineProperty(screen, 'availWidth', { get: () => 375 });
        """)
        
        return browser, page
    
    async def simulate_human_behavior(self, page):
        """æ¨¡æ‹Ÿäººç±»è¡Œä¸º"""
        # éšæœºç­‰å¾…
        await asyncio.sleep(random.uniform(*self.delay_range))
        
        # æ¨¡æ‹Ÿè§¦æ‘¸æ»‘åŠ¨
        await page.evaluate("""
            () => {
                window.scrollBy(0, Math.random() * 200);
            }
        """)
        
        await asyncio.sleep(random.uniform(0.5, 1.5))
    
    async def handle_verification(self, page):
        """å¤„ç†éªŒè¯é¡µé¢"""
        try:
            # æ£€æŸ¥æ˜¯å¦å‡ºç°éªŒè¯é¡µé¢
            verification_selectors = [
                'text=ç¯å¢ƒå¼‚å¸¸',
                'text=å®ŒæˆéªŒè¯åå³å¯ç»§ç»­è®¿é—®',
                'text=å»éªŒè¯',
                '.verify-wrap',
                '#verify_container'
            ]
            
            for selector in verification_selectors:
                if await page.locator(selector).count() > 0:
                    print("ğŸš¨ æ£€æµ‹åˆ°ç¯å¢ƒå¼‚å¸¸éªŒè¯é¡µé¢")
                    print("ğŸ“± è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨å®ŒæˆéªŒè¯...")
                    print("â³ è„šæœ¬å°†ç­‰å¾…éªŒè¯å®Œæˆ...")
                    
                    # ç­‰å¾…éªŒè¯å®Œæˆï¼Œæ£€æŸ¥é¡µé¢æ˜¯å¦è·³è½¬åˆ°æ­£å¸¸å†…å®¹
                    verification_completed = False
                    wait_time = 0
                    max_wait = 120  # æœ€å¤šç­‰å¾…2åˆ†é’Ÿ
                    
                    while not verification_completed and wait_time < max_wait:
                        await asyncio.sleep(5)
                        wait_time += 5
                        
                        # æ£€æŸ¥æ˜¯å¦å·²ç»è·³è½¬åˆ°æ­£å¸¸é¡µé¢
                        if await page.locator('#js_content').count() > 0:
                            verification_completed = True
                            print("âœ… éªŒè¯å®Œæˆï¼Œç»§ç»­æŠ“å–...")
                        elif await page.locator('text=ç¯å¢ƒå¼‚å¸¸').count() == 0:
                            verification_completed = True
                            print("âœ… é¡µé¢å·²æ›´æ–°ï¼Œç»§ç»­æŠ“å–...")
                        else:
                            print(f"â³ ç­‰å¾…éªŒè¯ä¸­... ({wait_time}s)")
                    
                    if not verification_completed:
                        print("âŒ éªŒè¯è¶…æ—¶ï¼Œè¯·æ‰‹åŠ¨è®¿é—®é“¾æ¥")
                        return False
                    
                    break
            
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç†éªŒè¯æ—¶å‡ºé”™: {e}")
            return False
    
    async def extract_article_content(self, page):
        """æå–æ–‡ç« å†…å®¹"""
        try:
            # ç­‰å¾…é¡µé¢å†…å®¹åŠ è½½
            await page.wait_for_selector('body', timeout=10000)
            
            # å…ˆå¤„ç†å¯èƒ½çš„éªŒè¯
            if not await self.handle_verification(page):
                return None
            
            # å°è¯•ç­‰å¾…æ–‡ç« å†…å®¹åŠ è½½
            content_selectors = ['#js_content', '.rich_media_content', 'article', '.article-content']
            content_loaded = False
            
            for selector in content_selectors:
                try:
                    await page.wait_for_selector(selector, timeout=5000)
                    content_loaded = True
                    break
                except PlaywrightTimeoutError:
                    continue
            
            if not content_loaded:
                print("âš ï¸ æœªèƒ½åŠ è½½åˆ°æ–‡ç« å†…å®¹ï¼Œå°è¯•æŠ“å–é¡µé¢å¯è§æ–‡æœ¬")
            
            # æŠ“å–æ–‡ç« æ•°æ®
            article_data = await page.evaluate("""
                () => {
                    // å°è¯•å¤šç§é€‰æ‹©å™¨è·å–æ ‡é¢˜
                    const getTitleElement = () => {
                        const selectors = [
                            '#activity-name',
                            '.rich_media_title',
                            'h1',
                            'h2',
                            '.title',
                            '[data-role="title"]'
                        ];
                        for (let selector of selectors) {
                            const element = document.querySelector(selector);
                            if (element && element.innerText.trim()) {
                                return element;
                            }
                        }
                        return null;
                    };
                    
                    // å°è¯•å¤šç§é€‰æ‹©å™¨è·å–å†…å®¹
                    const getContentElement = () => {
                        const selectors = [
                            '#js_content',
                            '.rich_media_content',
                            'article',
                            '.article-content',
                            '.content',
                            'main'
                        ];
                        for (let selector of selectors) {
                            const element = document.querySelector(selector);
                            if (element) {
                                return element;
                            }
                        }
                        return document.body;
                    };
                    
                    const titleElement = getTitleElement();
                    const contentElement = getContentElement();
                    
                    // è·å–ä½œè€…ä¿¡æ¯
                    const getAuthor = () => {
                        const authorSelectors = [
                            '#js_name',
                            '.rich_media_meta_nickname',
                            '.author',
                            '[data-role="author"]'
                        ];
                        for (let selector of authorSelectors) {
                            const element = document.querySelector(selector);
                            if (element && element.innerText.trim()) {
                                return element.innerText.trim();
                            }
                        }
                        return '';
                    };
                    
                    // è·å–å‘å¸ƒæ—¶é—´
                    const getPublishTime = () => {
                        const timeSelectors = [
                            '#publish_time',
                            '.rich_media_meta_text',
                            '.publish-time',
                            '[data-role="publish-time"]'
                        ];
                        for (let selector of timeSelectors) {
                            const element = document.querySelector(selector);
                            if (element && element.innerText.trim()) {
                                return element.innerText.trim();
                            }
                        }
                        return '';
                    };
                    
                    return {
                        url: window.location.href,
                        title: titleElement ? titleElement.innerText.trim() : document.title || '',
                        content: contentElement ? contentElement.innerText.trim() : '',
                        html_content: contentElement ? contentElement.innerHTML : '',
                        author: getAuthor(),
                        publish_time: getPublishTime(),
                        page_text: document.body.innerText.trim(),
                        images: Array.from(document.querySelectorAll('img')).map(img => ({
                            src: img.src,
                            alt: img.alt || '',
                            title: img.title || ''
                        })).filter(img => img.src && !img.src.includes('data:')),
                        links: Array.from(document.querySelectorAll('a')).map(a => ({
                            text: a.innerText.trim(),
                            href: a.href,
                            title: a.title || ''
                        })).filter(link => link.href && !link.href.startsWith('javascript:')),
                        scraped_at: new Date().toISOString()
                    };
                }
            """)
            
            return article_data
            
        except Exception as e:
            print(f"âŒ æå–å†…å®¹æ—¶å‡ºé”™: {e}")
            return None
    
    async def scrape_article(self, url):
        """æŠ“å–æ–‡ç« ä¸»å‡½æ•°"""
        print(f"ğŸš€ å¼€å§‹æŠ“å–: {url}")
        
        for attempt in range(self.max_retries):
            try:
                print(f"ğŸ“ å°è¯•ç¬¬ {attempt + 1} æ¬¡...")
                
                browser, page = await self.setup_browser()
                
                try:
                    # è®¿é—®é¡µé¢
                    print("ğŸŒ æ­£åœ¨è®¿é—®é¡µé¢...")
                    await page.goto(url, wait_until='domcontentloaded', timeout=30000)
                    
                    # æ¨¡æ‹Ÿäººç±»è¡Œä¸º
                    await self.simulate_human_behavior(page)
                    
                    # æå–å†…å®¹
                    print("ğŸ“– æ­£åœ¨æå–å†…å®¹...")
                    article_data = await self.extract_article_content(page)
                    
                    if article_data:
                        print("âœ… æŠ“å–æˆåŠŸ!")
                        return article_data
                    else:
                        print("âš ï¸ æœªèƒ½æå–åˆ°æœ‰æ•ˆå†…å®¹")
                        
                except PlaywrightTimeoutError:
                    print("â° é¡µé¢åŠ è½½è¶…æ—¶")
                except Exception as e:
                    print(f"âŒ æŠ“å–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                
                finally:
                    await browser.close()
                
                if attempt < self.max_retries - 1:
                    wait_time = random.uniform(5, 10)
                    print(f"â³ ç­‰å¾… {wait_time:.1f} ç§’åé‡è¯•...")
                    await asyncio.sleep(wait_time)
                    
            except Exception as e:
                print(f"âŒ ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")
        
        print("âŒ æ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†")
        return None
    
    async def save_result(self, data, output_dir="output"):
        """ä¿å­˜æŠ“å–ç»“æœ"""
        if not data:
            print("âŒ æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        title_clean = "".join(c for c in data.get('title', 'untitled')[:30] if c.isalnum() or c in (' ', '-', '_')).strip()
        
        # ä¿å­˜ JSON æ–‡ä»¶
        json_file = output_path / f"{timestamp}_{title_clean}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ JSON å·²ä¿å­˜: {json_file}")
        
        # ä¿å­˜çº¯æ–‡æœ¬æ–‡ä»¶
        txt_file = output_path / f"{timestamp}_{title_clean}.txt"
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(f"æ ‡é¢˜: {data.get('title', 'æ— æ ‡é¢˜')}\n")
            f.write(f"ä½œè€…: {data.get('author', 'æœªçŸ¥')}\n")
            f.write(f"å‘å¸ƒæ—¶é—´: {data.get('publish_time', 'æœªçŸ¥')}\n")
            f.write(f"æŠ“å–æ—¶é—´: {data.get('scraped_at', 'æœªçŸ¥')}\n")
            f.write(f"é“¾æ¥: {data.get('url', 'æœªçŸ¥')}\n")
            f.write("=" * 50 + "\n\n")
            f.write(data.get('content', 'æ— å†…å®¹'))
        print(f"ğŸ“„ æ–‡æœ¬å·²ä¿å­˜: {txt_file}")
        
        # ä¿å­˜ HTML æ–‡ä»¶
        html_file = output_path / f"{timestamp}_{title_clean}.html"
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{data.get('title', 'æ— æ ‡é¢˜')}</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; padding: 20px; }}
        .meta {{ color: #666; font-size: 14px; margin-bottom: 20px; }}
        .content {{ margin-top: 20px; }}
    </style>
</head>
<body>
    <h1>{data.get('title', 'æ— æ ‡é¢˜')}</h1>
    <div class="meta">
        <p>ä½œè€…: {data.get('author', 'æœªçŸ¥')}</p>
        <p>å‘å¸ƒæ—¶é—´: {data.get('publish_time', 'æœªçŸ¥')}</p>
        <p>æŠ“å–æ—¶é—´: {data.get('scraped_at', 'æœªçŸ¥')}</p>
        <p>åŸæ–‡é“¾æ¥: <a href="{data.get('url', '#')}" target="_blank">{data.get('url', 'æœªçŸ¥')}</a></p>
    </div>
    <div class="content">
        {data.get('html_content', data.get('content', 'æ— å†…å®¹'))}
    </div>
</body>
</html>
            """)
        print(f"ğŸŒ HTML å·²ä¿å­˜: {html_file}")
    
    async def run(self, url):
        """è¿è¡ŒæŠ“å–å™¨"""
        self.playwright = await async_playwright().start()
        
        try:
            data = await self.scrape_article(url)
            await self.save_result(data)
            
            if data:
                print("\nğŸ“Š æŠ“å–æ‘˜è¦:")
                print(f"ğŸ“° æ ‡é¢˜: {data.get('title', 'æ— æ ‡é¢˜')}")
                print(f"ğŸ‘¤ ä½œè€…: {data.get('author', 'æœªçŸ¥')}")
                print(f"ğŸ“… å‘å¸ƒæ—¶é—´: {data.get('publish_time', 'æœªçŸ¥')}")
                print(f"ğŸ“ å†…å®¹é•¿åº¦: {len(data.get('content', ''))} å­—ç¬¦")
                print(f"ğŸ–¼ï¸ å›¾ç‰‡æ•°é‡: {len(data.get('images', []))}")
                print(f"ğŸ”— é“¾æ¥æ•°é‡: {len(data.get('links', []))}")
            
            return data
            
        finally:
            await self.playwright.stop()


async def main():
    """ä¸»å‡½æ•°"""
    # ç›®æ ‡URL
    url = "https://mp.weixin.qq.com/s/5kBJaZenOxfRWMZyoFfppQ"
    
    # åˆ›å»ºæŠ“å–å™¨å®ä¾‹
    scraper = WeChatScraper()
    
    # è¿è¡ŒæŠ“å–
    try:
        result = await scraper.run(url)
        if result:
            print("ğŸ‰ æŠ“å–å®Œæˆ!")
        else:
            print("ğŸ˜ æŠ“å–å¤±è´¥")
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­æŠ“å–")
    except Exception as e:
        print(f"âŒ ç¨‹åºé”™è¯¯: {e}")


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ•·ï¸  å¾®ä¿¡å…¬ä¼—å·æ–‡ç« æŠ“å–å™¨")
    print("=" * 60)
    
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main()) 